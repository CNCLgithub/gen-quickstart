{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Iterative Inference Programming in Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces the basics of inference programming in Gen using **iterative inference programs**, which include **Markov chain Monte Carlo (MCMC) algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The task: curve-fitting with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a dataset of points in the $x,y$ plane that is _mostly_ explained by a linear relationship, but which also has several outliers. \\\n",
    "We will \n",
    "1. automatically identify the outliers and \n",
    "2. find a linear relationship (a slope & intercept, as well as an inherent noise level) that explains the rest of the points:\n",
    "\n",
    "<img src=\"../tutorials/images/example-inference.png\" alt=\"See https://dspace.mit.edu/bitstream/handle/1721.1/119255/MIT-CSAIL-TR-2018-020.pdf, Figure 2(a))\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 1.** [Writing the model](#writing-model)\n",
    "\n",
    "**Section 2.** [Visualizing the model's behavior](#visualizing)\n",
    "\n",
    "**Section 3.** [ The problem with generic importance sampling ](#importance)\n",
    "\n",
    "**Section 4.1** [MCMC Inference: Introduction](#mcmc-1)\n",
    "\n",
    "**Section 4.2** [MCMC Inference: Block Resimulation](#mcmc-2)\n",
    "\n",
    "**Section 4.3** [MCMC Inference: Gaussian Drift](#mcmc-3)\n",
    "\n",
    "**Section 4.3** [MCMC Inference: Data-driven proposals based on heuristics](#mcmc-4)\n",
    "\n",
    "**Section 5** [Data-driven proposals in visual object perception - a very short teaser](#shape-inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "import Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Writing the model <a name=\"writing-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin, as usual, by writing a model: a Julia function responsible (conceptually) for simulating a fake dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function model(xs::Vector{Float64})\n",
    "    slope = @trace(normal(0, 2), :slope)\n",
    "    intercept = @trace(normal(0, 2), :intercept)\n",
    "    noise = @trace(gamma(1, 1), :noise)\n",
    "    \n",
    "    # THIS PART IS NEW: it allows a more robust inference scheme by modeling outliers.\n",
    "    # prob_outlier is the proportion of the dataset that don't fit a linear relationship (outliers) \n",
    "    prob_outlier = @trace(uniform(0, 1), :prob_outlier)\n",
    "    \n",
    "    # Next, we generate the actual y coordinates.\n",
    "    n = length(xs)\n",
    "    ys = Vector{Float64}(undef, n)\n",
    "    \n",
    "    for i = 1:n\n",
    "        # Decide whether this point is an outlier, and set\n",
    "        # mean and standard deviation accordingly\n",
    "        if @trace(bernoulli(prob_outlier), :data => i => :is_outlier)\n",
    "            (mu, std) = (0., 10.)\n",
    "        else\n",
    "            (mu, std) = (xs[i] * slope + intercept, noise)\n",
    "        end\n",
    "        # Sample a y value for this point\n",
    "        ys[i] = @trace(normal(mu, std), :data => i => :y)\n",
    "    end\n",
    "    ys\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does what we want: it samples several parameters of the data-generating process, then generates data accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the causal diagram:\n",
    "\n",
    "<img src=\"./images/line_3.png\" alt=\"Causal diagram: Line with outliers\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What our model is doing: visualizing the prior "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize what our model is doing by drawing some samples from the prior. \\\n",
    "We use the GenViz library here which we will not focus on in this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GenViz\n",
    "\n",
    "function serialize_trace(trace)\n",
    "    assmt = Gen.get_choices(trace)\n",
    "    (xs,) = Gen.get_args(trace)\n",
    "    Dict(\"slope\" => assmt[:slope],\n",
    "        \"intercept\" => assmt[:intercept],\n",
    "        \"inlier_std\" => assmt[:noise],\n",
    "        \"y-coords\" => [assmt[:data => i => :y] for i in 1:length(xs)],\n",
    "        \"outliers\" => [assmt[:data => i => :is_outlier] for i in 1:length(xs)])\n",
    "end;\n",
    "\n",
    "server = VizServer(8091);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate some data and draw it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get some x coordinates and initialize a visualization\n",
    "xs = collect(range(-5, stop=5, length=20))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"../tutorials/regression-viz/dist\"), [xs])\n",
    "\n",
    "# Generate ten traces and draw them into the visualization\n",
    "for i=1:10\n",
    "    (trace, _) = Gen.generate(model, (xs,))\n",
    "    ys = Gen.get_retval(trace)\n",
    "    putTrace!(viz, \"t$(i)\", serialize_trace(trace))\n",
    "end\n",
    "\n",
    "# Display the visualization in this notebook\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that an outlier can occur anywhere — including close to the line — and that our model is capable of generating datasets in which the vast majority of points are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The problem with generic importance sampling  <a name=\"generic-importance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To motivate the need for more complex inference algorithms, let's begin by using the simple importance sampling method from the previous tutorial, and thinking about where it fails.\n",
    "\n",
    "First, let us create a synthetic dataset to do inference _about_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_synthetic_dataset(n)\n",
    "    Random.seed!(1)\n",
    "    prob_outlier = 0.2\n",
    "    true_inlier_noise = 0.5\n",
    "    true_outlier_noise = 5.0\n",
    "    true_slope = -1\n",
    "    true_intercept = 2\n",
    "    xs = collect(range(-5, stop=5, length=n))\n",
    "    ys = Float64[]\n",
    "    for (i, x) in enumerate(xs)\n",
    "        if rand() < prob_outlier\n",
    "            y = randn() * true_outlier_noise\n",
    "        else\n",
    "            y = true_slope * x + true_intercept + randn() * true_inlier_noise\n",
    "        end\n",
    "        push!(ys, y)\n",
    "    end\n",
    "    (xs, ys)\n",
    "end\n",
    "    \n",
    "(xs, ys) = make_synthetic_dataset(20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Gen, we express our _observations_ as an _Assignment_ that constrains the values of certain random choices to equal their observed values. Let's write a helper for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_constraints(ys::Vector{Float64})\n",
    "    constraints = Gen.choicemap()\n",
    "    for i=1:length(ys)\n",
    "        constraints[:data => i => :y] = ys[i]\n",
    "    end\n",
    "    constraints\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply it to our dataset's vector of `ys` to make a set of constraints for doing inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = make_constraints(ys);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the library function `importance_resampling` to draw approximate posterior samples given those observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function logmeanexp(scores)\n",
    "    logsumexp(scores) - log(length(scores))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = Viz(server, joinpath(@__DIR__, \"../tutorials/regression-viz/dist\"), [xs])\n",
    "log_probs = Vector{Float64}(undef, 10)\n",
    "for i=1:10\n",
    "    (tr, _) = Gen.importance_resampling(model, (xs,), observations, 2000)\n",
    "    putTrace!(viz, \"t$(i)\", serialize_trace(tr))\n",
    "    log_probs[i] = Gen.get_score(tr)\n",
    "end\n",
    "displayInNotebook(viz)\n",
    "println(\"Average log probability: $(logmeanexp(log_probs))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that importance sampling hasn't completely failed: it generally finds a reasonable position for the line. But the details are off: there is little logic to the outlier classification, and the inferred noise around the line is too wide. The problem is that there are just too many variables to get right, and so sampling everything in one go is highly unlikely to produce a perfect hit.\n",
    "\n",
    "In the remainder of this notebook, we'll explore techniques for finding the right solution _iteratively_, beginning with an initial guess and making many small changes, until we achieve a reasonable posterior sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MCMC Inference  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 What is MCMC? <a name=\"mcmc-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've only been sampling traces that were indepent of each other. Let's now iteratively build chains of such traces where an iteration brings us closer to a good explanation of observations. \n",
    "\n",
    "The general shape of an MCMC algorithm is as follows: \n",
    "- We begin by **sampling an intial setting of all unobserved variables**; in Gen, we produce an initial _trace_ consistent with (but not necessarily _probable_ given) our observations. \n",
    "- Then, in a long-running loop, **we make small, stochastic changes to the trace**; in order for the algorithm to be asymptotically correct, these stochastic updates must satisfy certain probabilistic properties. \n",
    "\n",
    "One common way of ensuring that the updates do satisfy those properties is to compute a  **Metropolis-Hastings acceptance ratio**. Essentially, after proposing a change to a trace, we add an \"accept or reject\" step that stochastically decides whether to commit the update or to revert it.\n",
    "\n",
    "Gen's `metropolis_hastings` function _automatically_ adds this \"accept/reject\" check (including the correct computation of the probability of acceptance or rejection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 2 Block Resimulation <a name=\"mcmc-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest strategies we can use is called Resimulation MH, and it works as follows.\n",
    "\n",
    "We begin, as in most iterative inference algorithms, by sampling an initial trace from our model, fixing the observed choices to their observed values.\n",
    "\n",
    "```julia\n",
    "# Gen's `initialize` function accepts a model, a tuple of arguments to the model,\n",
    "# and an Assignment representing observations (or constraints to satisfy). It returns\n",
    "# a complete trace consistent with the observations, and an importance weight.\n",
    "(tr, _) = initialize(model, (xs,), observations)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in each iteration of our program, we propose changes to all our model's variables in \"blocks,\" by erasing a set of variables from our current trace and _resimulating_ them from the model. After resimulating each block of choices, we perform an accept/reject step, deciding whether the proposed changes are worth making. \n",
    "\n",
    "```julia\n",
    "# Pseudocode\n",
    "for iter=1:500\n",
    "    tr = maybe_update_block_1(tr)\n",
    "    tr = maybe_update_block_2(tr)\n",
    "    ...\n",
    "    tr = maybe_update_block_n(tr)\n",
    "end\n",
    "```\n",
    "\n",
    "For the regression problem, here is one possible blocking of choices:\n",
    "\n",
    "**Block 1: `slope`, `intercept`, and `noise`.** These parameters determine the linear relationship; resimulating them is like picking a new line. We know from our importance sampling experiment above that before too long, we're bound to sample something close to the right line.\n",
    "\n",
    "**Blocks 2 through N+1: Each `is_outlier`, in its own block.** One problem we saw with importance sampling in this problem was that it tried to sample _every_ outlier classification at once, when in reality the chances of a single sample that correctly classifies all the points are very low. Here, we can choose to resimulate each `is_outlier` choice separately, and for each one, decide whether to use the resimulated value or not.\n",
    "\n",
    "**Block N+2: `prob_outlier`.** Finally, we can propose a new `prob_outlier` value; in general, we can expect to accept the proposal when it is in line with the current hypothesized proportion of `is_outlier` choices that are set to `true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a single block resimulation update of a trace.\n",
    "function block_resimulation_update(tr)\n",
    "    # Block 1: Update the line's parameters\n",
    "    line_params = select(:noise, :slope, :intercept)\n",
    "    (tr, _) = mh(tr, line_params)\n",
    "    \n",
    "    # Blocks 2-N+1: Update the outlier classifications\n",
    "    (xs,) = get_args(tr)\n",
    "    n = length(xs)\n",
    "    for i=1:n\n",
    "        (tr, _) = mh(tr, select(:data => i => :is_outlier))\n",
    "    end\n",
    "    \n",
    "    # Block N+2: Update the prob_outlier parameter\n",
    "    (tr, _) = mh(tr, select(:prob_outlier))\n",
    "    \n",
    "    # Return the updated trace\n",
    "    tr\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left is to (a) obtain an initial trace, and then (b) run that update in a loop for as long as we'd like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function block_resimulation_inference(xs, ys)\n",
    "    observations = make_constraints(ys)\n",
    "    (tr, _) = generate(model, (xs,), observations)\n",
    "    for iter=1:500\n",
    "        tr = block_resimulation_update(tr)\n",
    "    end\n",
    "    tr\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Vector{Float64}(undef, 10)\n",
    "for i=1:10\n",
    "    @time tr = block_resimulation_inference(xs, ys)\n",
    "    scores[i] = get_score(tr)\n",
    "end\n",
    "println(\"Log probability: \", logmeanexp(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that this is **significantly better than importance sampling**, even if we run importance sampling for about the same amount of (wall-clock) time per sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Vector{Float64}(undef, 10)\n",
    "for i=1:10\n",
    "    @time (tr, _) = importance_resampling(model, (xs,), observations, 17000)\n",
    "    scores[i] = get_score(tr)\n",
    "end\n",
    "println(\"Log probability: \", logmeanexp(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's one thing to see a log probability increase; it's better to understand what the inference algorithm is actually doing, and to see _why_ it's doing better.\n",
    "\n",
    "A great tool for debugging and improving MCMC algorithms is visualization. We can use GenViz's `displayInNotebook(viz) do ... end` syntax to produce an animated visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz = Viz(server, joinpath(@__DIR__, \"../tutorials/regression-viz/dist\"), [xs, ys])\n",
    "Random.seed!(2)\n",
    "displayInNotebook(viz) do\n",
    "    (tr, _) = generate(model, (xs,), observations)\n",
    "    putTrace!(viz, \"t\", serialize_trace(tr))\n",
    "    for iter = 1:500\n",
    "        tr = block_resimulation_update(tr)\n",
    "        \n",
    "        # Visualize and sleep for clearer animation\n",
    "        putTrace!(viz, \"t\", serialize_trace(tr))\n",
    "        sleep(0.01)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Gaussian Drift MH  <a name=\"mcmc-3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've seen one form of incremental trace update:\n",
    "\n",
    "```julia\n",
    "(tr, did_accept) = mh(tr, select(:address1, :address2, ...))\n",
    "```\n",
    "\n",
    "This update is incremental in that it only proposes changes to part of a trace (the selected addresses). But when computing _what_ changes to propose, it ignores the current state completely and resimulates all-new values from the model.\n",
    "\n",
    "That wholesale resimulation of values is often not the best way to search for improvements. To that end, Gen also offers a more general flavor of MH:\n",
    "\n",
    "```julia\n",
    "(tr, did_accept) = mh(tr, custom_proposal, custom_proposal_args)\n",
    "```\n",
    "\n",
    "A \"custom proposal\" is just what it sounds like: whereas before, we were using the _default resimulation proposal_ to come up with new values for the selected addresses, we can now pass in a generative function that samples proposed values however it wants.\n",
    "\n",
    "For example, here is a custom proposal that takes in a current trace, and proposes a new slope and intercept by randomly perturbing the existing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function line_proposal(trace)\n",
    "    choices = get_choices(trace)\n",
    "    slope = @trace(normal(choices[:slope], 0.5), :slope)\n",
    "    intercept = @trace(normal(choices[:intercept], 0.5), :intercept)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is often called a **\"Gaussian drift\" proposal**, because it essentially amounts to proposing steps of a random walk. (What makes it different from a random walk is that we will still use an MH accept/reject step to make sure we don't wander into areas of very low probability.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the proposal, we write:\n",
    "\n",
    "```julia\n",
    "(tr, did_accept) = mh(tr, line_proposal, ())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's swap it into our update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gaussian_drift_update(tr)\n",
    "    # Block 1: Gaussian drift on line params\n",
    "    (tr, _) = mh(tr, line_proposal, ())\n",
    "    (tr, w) = mh(tr, select(:noise))\n",
    "    \n",
    "    # Block 2-N+1: Update the outlier classifications\n",
    "    (xs,) = get_args(tr)\n",
    "    n = length(xs)\n",
    "    for i=1:n\n",
    "        (tr, _) = mh(tr, select(:data => i => :is_outlier))\n",
    "    end\n",
    "    \n",
    "    # Block N+2: Update the prob_outlier parameter\n",
    "    (tr, w) = mh(tr, select(:prob_outlier))\n",
    "    tr\n",
    "end;\n",
    "\n",
    "\n",
    "# Only FYI: This is the old inference scheme:\n",
    "\"\"\"function block_resimulation_update(tr)\n",
    "    # Block 1: Update the line's parameters\n",
    "    line_params = select(:noise, :slope, :intercept)\n",
    "    (tr, _) = mh(tr, line_params)\n",
    "    \n",
    "    # Blocks 2-N+1: Update the outlier classifications\n",
    "    (xs,) = get_args(tr)\n",
    "    n = length(xs)\n",
    "    for i=1:n\n",
    "        (tr, _) = mh(tr, select(:data => i => :is_outlier))\n",
    "    end\n",
    "    \n",
    "    # Block N+2: Update the prob_outlier parameter\n",
    "    (tr, _) = mh(tr, select(:prob_outlier))\n",
    "    \n",
    "    # Return the updated trace\n",
    "    tr\n",
    "end;\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the Gaussian Drift proposal visually with our old algorithm, we can see how the new behavior helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz = Viz(server, joinpath(@__DIR__, \"../tutorials/regression-viz/dist\"), [xs, ys])\n",
    "\n",
    "# Set random seed for a reproducible animation\n",
    "Random.seed!(30)\n",
    "\n",
    "# Create the animation\n",
    "displayInNotebook(viz) do\n",
    "    # Get an initial trace\n",
    "    (tr1, _) = generate(model, (xs,), observations)\n",
    "    tr2 = tr1\n",
    "    \n",
    "    # Visualize the initial trace twice\n",
    "    putTrace!(viz, 1, serialize_trace(tr1))\n",
    "    putTrace!(viz, 2, serialize_trace(tr2))\n",
    "    sleep(1)\n",
    "    \n",
    "    # Improve both traces\n",
    "    for iter = 1:400\n",
    "        # Gaussian drift update in trace 1\n",
    "        tr1 = gaussian_drift_update(tr1)\n",
    "        # Block resimulation update in trace 2\n",
    "        tr2 = block_resimulation_update(tr2)\n",
    "        \n",
    "        # Visualize and sleep for clearer animation\n",
    "        putTrace!(viz, 1, serialize_trace(tr1))\n",
    "        putTrace!(viz, 2, serialize_trace(tr2))\n",
    "        sleep(0.02)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more quantitative comparison demonstrates that our change has definitely improved our inference quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1)\n",
    "function gaussian_drift_inference()\n",
    "    (tr, _) = generate(model, (xs,), observations)\n",
    "    for iter=1:500\n",
    "        tr = gaussian_drift_update(tr)\n",
    "    end\n",
    "    tr\n",
    "end\n",
    "\n",
    "scores = Vector{Float64}(undef, 10)\n",
    "for i=1:10\n",
    "    @time tr = gaussian_drift_inference()\n",
    "    scores[i] = get_score(tr)\n",
    "end\n",
    "println(\"Log probability: \", logmeanexp(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Data-driven proposals: heuristics to guide the process  <a name=\"mcmc-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll look at another strategy for improving MCMC inference: using arbitrary heuristics to make smarter proposals. In particular, we'll use a method called \"Random Sample Consensus\" (or RANSAC) to quickly find promising settings of the slope and intercept parameters.\n",
    "\n",
    "RANSAC works as follows:\n",
    "1. We repeatedly choose a small random subset of the points, say, of size 3.\n",
    "2. We do least-squares linear regression to find a line of best fit for those points.\n",
    "3. We count how many points (from the entire set) are near the line we found.\n",
    "4. After a suitable number of iterations (say, 10), we return the line that had the highest score.\n",
    "\n",
    "Here's our implementation of the algorithm in Julia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import StatsBase\n",
    "\n",
    "struct RANSACParams\n",
    "    # the number of random subsets to try\n",
    "    iters::Int\n",
    "\n",
    "    # the number of points to use to construct a hypothesis\n",
    "    subset_size::Int\n",
    "\n",
    "    # the error threshold below which a datum is considered an inlier\n",
    "    eps::Float64\n",
    "    \n",
    "    function RANSACParams(iters, subset_size, eps)\n",
    "        if iters < 1\n",
    "            error(\"iters < 1\")\n",
    "        end\n",
    "        new(iters, subset_size, eps)\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "function ransac(xs::Vector{Float64}, ys::Vector{Float64}, params::RANSACParams)\n",
    "    best_num_inliers::Int = -1\n",
    "    best_slope::Float64 = NaN\n",
    "    best_intercept::Float64 = NaN\n",
    "    for i=1:params.iters\n",
    "        # select a random subset of points\n",
    "        rand_ind = StatsBase.sample(1:length(xs), params.subset_size, replace=false)\n",
    "        subset_xs = xs[rand_ind]\n",
    "        subset_ys = ys[rand_ind]\n",
    "        \n",
    "        # estimate slope and intercept using least squares\n",
    "        A = hcat(subset_xs, ones(length(subset_xs)))\n",
    "        slope, intercept = A\\subset_ys\n",
    "        \n",
    "        ypred = intercept .+ slope * xs\n",
    "\n",
    "        # count the number of inliers for this (slope, intercept) hypothesis\n",
    "        inliers = abs.(ys - ypred) .< params.eps\n",
    "        num_inliers = sum(inliers)\n",
    "\n",
    "        if num_inliers > best_num_inliers\n",
    "            best_slope, best_intercept = slope, intercept\n",
    "            best_num_inliers = num_inliers\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # return the hypothesis that resulted in the most inliers\n",
    "    (best_slope, best_intercept)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now wrap it in a Gen proposal that calls out to RANSAC, then samples a slope and intercept near the one it proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function ransac_proposal(prev_trace, xs, ys)\n",
    "    (slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\n",
    "    @trace(normal(slope, 0.1), :slope)\n",
    "    @trace(normal(intercept, 1.0), :intercept)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One iteration of our update algorithm will now look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ransac_update(tr)\n",
    "    # Use RANSAC to (potentially) jump to a better line from wherever we are\n",
    "    (tr, _) = mh(tr, ransac_proposal, (xs, ys))\n",
    "    \n",
    "    # Spend a while refining the parameters, using Gaussian drift\n",
    "    # to tune the slope and intercept, and resimulation for the noise\n",
    "    # and outliers.\n",
    "    for j=1:20\n",
    "        (tr, _) = mh(tr, select(:prob_outlier))\n",
    "        (tr, _) = mh(tr, select(:noise))\n",
    "        (tr, _) = mh(tr, line_proposal, ())\n",
    "        # Reclassify outliers\n",
    "        for i=1:length(get_args(tr)[1])\n",
    "            (tr, _) = mh(tr, select(:data => i => :is_outlier))\n",
    "        end\n",
    "    end\n",
    "    tr\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run our main loop for just 5 iterations, and achieve pretty good results. (Of course, since we do 20 inner loop iterations in `ransac_update`, this is really closer to 100 iterations.) The running time is significantly lower than before, without a real dip in quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ransac_inference()\n",
    "    (slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\n",
    "    slope_intercept_init = choicemap()\n",
    "    slope_intercept_init[:slope] = slope\n",
    "    slope_intercept_init[:intercept] = intercept\n",
    "    (tr, _) = generate(model, (xs,), merge(observations, slope_intercept_init))\n",
    "    for iter=1:5\n",
    "        tr = ransac_update(tr)\n",
    "    end\n",
    "    tr\n",
    "end\n",
    "\n",
    "scores = Vector{Float64}(undef, 10)\n",
    "for i=1:10\n",
    "    @time tr = ransac_inference()\n",
    "    scores[i] = get_score(tr)\n",
    "end\n",
    "println(\"Log probability: \", logmeanexp(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz = Viz(server, joinpath(@__DIR__, \"../tutorials/regression-viz/dist\"), [xs, ys])\n",
    "displayInNotebook(viz) do\n",
    "    (slope, intercept) = ransac(xs, ys, RANSACParams(10, 3, 1.))\n",
    "    slope_intercept_init = choicemap()\n",
    "    slope_intercept_init[:slope] = slope\n",
    "    slope_intercept_init[:intercept] = intercept\n",
    "    (tr, _) = generate(model, (xs,), merge(observations, slope_intercept_init))\n",
    "    putTrace!(viz, \"t\", serialize_trace(tr))\n",
    "    for iter = 1:5\n",
    "        (tr, _) = mh(tr, ransac_proposal, (xs, ys))\n",
    "    \n",
    "        # Spend a while refining the parameters, using Gaussian drift\n",
    "        # to tune the slope and intercept, and resimulation for the noise\n",
    "        # and outliers.\n",
    "        for j=1:20\n",
    "            (tr, _) = mh(tr, select(:prob_outlier))\n",
    "            (tr, _) = mh(tr, select(:noise))\n",
    "            (tr, _) = mh(tr, line_proposal, ())\n",
    "            # Reclassify outliers\n",
    "            for i=1:length(get_args(tr)[1])\n",
    "                (tr, _) = mh(tr, select(:data => i => :is_outlier))\n",
    "            end\n",
    "            putTrace!(viz, \"t\", serialize_trace(tr))\n",
    "            sleep(0.1)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data-driven proposals in visual object perception - a very short teaser <a name=\"shape-inference\"></a>\n",
    "\n",
    "Going back to our analysis by synthesis framework for visual perception, we can analogously use low-level cues (captured by, for example, a Convolutional Neural Network) in observations to inform our inference algorithm. Since we can accelerate top-down inference dramatically using this method, we refer to this technique as \"efficient inverse graphics\". \n",
    "\n",
    "<img src=\"./images/shape_inference_pipeline_data-driven.jpg\" alt=\"Adapted from https://github.com/junyanz/VON\" width=\"800\"/>\n",
    "\n",
    "Check out https://www.biorxiv.org/content/10.1101/282798v2 (Yildirim, I., Belledonne, M., Freiwald, W., & Tenenbaum, J.B. Efficient inverse graphics in biological face processing. 2019) to read more about this technique in the domain of faces and how it relates to monkey neurophsyiology and human behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
